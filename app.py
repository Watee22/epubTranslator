import streamlit as st
import os
import json
import pandas as pd
import tempfile
from epubtranslator import translate_epub, extract_terms, load_glossary
import threading

st.set_page_config(page_title="EPUB ç¿»è¯‘å™¨", page_icon="ğŸ“š", layout="wide")

# åˆ›å»ºä¾§è¾¹æ 
st.sidebar.title("EPUB ç¿»è¯‘å™¨")
st.sidebar.markdown("å°†è‹±æ–‡ EPUB æ–‡ä»¶ç¿»è¯‘æˆä¸­æ–‡")

# ä¸Šä¼  EPUB æ–‡ä»¶
uploaded_file = st.sidebar.file_uploader("ä¸Šä¼  EPUB æ–‡ä»¶", type=["epub"])

if uploaded_file is not None:
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_dir = tempfile.mkdtemp()
    input_path = os.path.join(temp_dir, uploaded_file.name)
    output_path = os.path.join(temp_dir, uploaded_file.name.replace('.epub', '_cn.epub'))
    
    with open(input_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.sidebar.success(f"æ–‡ä»¶å·²ä¸Šä¼ : {uploaded_file.name}")
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    st.title(f"ç¿»è¯‘ EPUB: {uploaded_file.name}")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["ä¸“æœ‰åè¯", "ç¿»è¯‘è®¾ç½®", "å¼€å§‹ç¿»è¯‘"])
    
    # æ ‡ç­¾é¡µ1ï¼šä¸“æœ‰åè¯æå–å’Œç¼–è¾‘
    with tab1:
        st.header("ä¸“æœ‰åè¯è¯å…¸")
        
        # æå–ä¸“æœ‰åè¯çš„æŒ‰é’®
        if st.button("ä» EPUB ä¸­æå–ä¸“æœ‰åè¯"):
            with st.spinner("æ­£åœ¨æå–ä¸“æœ‰åè¯..."):
                terms = extract_terms(input_path)
                
                # å°†æå–çš„è¯æ¡æ˜¾ç¤ºåœ¨è¡¨æ ¼ä¸­
                if terms:
                    # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ç¿»è¯‘åˆ—çš„ DataFrame
                    df = pd.DataFrame({
                        "ä¸“æœ‰åè¯": terms,
                        "ä¸­æ–‡ç¿»è¯‘": [""] * len(terms)
                    })
                    
                    # å°† DataFrame ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.terms_df = df
                    
                    # æ˜¾ç¤ºå¯ç¼–è¾‘çš„è¡¨æ ¼
                    edited_df = st.data_editor(
                        st.session_state.terms_df, 
                        use_container_width=True,
                        num_rows="dynamic",
                        hide_index=True
                    )
                    st.session_state.terms_df = edited_df
                    
                    # æä¾›ä¸‹è½½æŒ‰é’®
                    col1, col2 = st.columns(2)
                    
                    # JSON ä¸‹è½½æŒ‰é’®
                    with col1:
                        if st.button("ä¸‹è½½è¯æ±‡è¡¨ä¸º JSON"):
                            # åˆ›å»ºè¯æ±‡è¡¨å­—å…¸
                            glossary = {row["ä¸“æœ‰åè¯"]: row["ä¸­æ–‡ç¿»è¯‘"] for _, row in edited_df.iterrows() if row["ä¸­æ–‡ç¿»è¯‘"]}
                            # ä¿å­˜ä¸º JSON
                            base_name = os.path.splitext(os.path.basename(input_path))[0]
                            glossary_path = os.path.join(temp_dir, f"{base_name}_glossary.json")
                            with open(glossary_path, "w", encoding="utf-8") as f:
                                json.dump(glossary, f, ensure_ascii=False, indent=2)
                            
                            # æä¾›ä¸‹è½½é“¾æ¥
                            with open(glossary_path, "r", encoding="utf-8") as f:
                                st.download_button(
                                    label="ä¸‹è½½ JSON æ–‡ä»¶",
                                    data=f,
                                    file_name=f"{base_name}_glossary.json",
                                    mime="application/json"
                                )
                    
                    # Excel ä¸‹è½½æŒ‰é’®
                    with col2:
                        if st.button("ä¸‹è½½è¯æ±‡è¡¨ä¸º Excel"):
                            # ä¿å­˜ä¸º Excel
                            base_name = os.path.splitext(os.path.basename(input_path))[0]
                            excel_path = os.path.join(temp_dir, f"{base_name}_glossary.xlsx")
                            
                            # ä»æ•°æ®æ¡†ä¸­ä¿å­˜éç©ºç¿»è¯‘
                            glossary_df = edited_df[edited_df["ä¸­æ–‡ç¿»è¯‘"].notna() & (edited_df["ä¸­æ–‡ç¿»è¯‘"] != "")]
                            
                            # å¦‚æœæœ‰ç©ºè¡Œä¹Ÿä¿ç•™ï¼ˆå…¨éƒ¨ä¿å­˜ï¼‰
                            if len(glossary_df) == 0:
                                glossary_df = edited_df
                                
                            # ä¿å­˜ä¸ºExcel
                            glossary_df.to_excel(excel_path, index=False)
                            
                            # æä¾›ä¸‹è½½é“¾æ¥
                            with open(excel_path, "rb") as f:
                                st.download_button(
                                    label="ä¸‹è½½ Excel æ–‡ä»¶",
                                    data=f,
                                    file_name=f"{base_name}_glossary.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                else:
                    st.info("æœªæ‰¾åˆ°ä¸“æœ‰åè¯")
                    
        # ä¸Šä¼ è‡ªå®šä¹‰è¯æ±‡è¡¨ï¼ˆæ–°å¢æ”¯æŒExcelæ ¼å¼ï¼‰
        st.subheader("ä¸Šä¼ è‡ªå®šä¹‰è¯æ±‡è¡¨")
        uploaded_glossary = st.file_uploader("ä¸Šä¼  JSON æˆ– Excel æ ¼å¼çš„è¯æ±‡è¡¨", type=["json", "xlsx", "xls"])
        
        if uploaded_glossary is not None:
            try:
                # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
                if uploaded_glossary.name.endswith(('.xlsx', '.xls')):
                    # è¯»å–Excel
                    glossary_df = pd.read_excel(uploaded_glossary)
                    
                    # ç¡®ä¿æœ‰æ­£ç¡®çš„åˆ—å
                    if 'ä¸“æœ‰åè¯' in glossary_df.columns and 'ä¸­æ–‡ç¿»è¯‘' in glossary_df.columns:
                        # è½¬æ¢ä¸ºå­—å…¸
                        glossary_data = dict(zip(glossary_df['ä¸“æœ‰åè¯'], glossary_df['ä¸­æ–‡ç¿»è¯‘']))
                    else:
                        # å‡è®¾å‰ä¸¤åˆ—æ˜¯æœ¯è¯­å’Œç¿»è¯‘
                        col_names = glossary_df.columns.tolist()
                        if len(col_names) >= 2:
                            glossary_df.columns = ['ä¸“æœ‰åè¯', 'ä¸­æ–‡ç¿»è¯‘'] + col_names[2:]
                            glossary_data = dict(zip(glossary_df['ä¸“æœ‰åè¯'], glossary_df['ä¸­æ–‡ç¿»è¯‘']))
                        else:
                            st.error("Excel æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼šè‡³å°‘éœ€è¦ä¸¤åˆ—ï¼ˆä¸“æœ‰åè¯å’Œä¸­æ–‡ç¿»è¯‘ï¼‰")
                            glossary_data = {}
                else:
                    # è¯»å–JSON
                    glossary_data = json.load(uploaded_glossary)
                
                # æ˜¾ç¤ºåŠ è½½ä¿¡æ¯
                if glossary_data:
                    st.success(f"å·²ä¸Šä¼ è¯æ±‡è¡¨ï¼ŒåŒ…å« {len(glossary_data)} ä¸ªè¯æ¡")
                    
                    # è½¬æ¢ä¸º DataFrame å¹¶æ˜¾ç¤º
                    glossary_df = pd.DataFrame({
                        "ä¸“æœ‰åè¯": list(glossary_data.keys()),
                        "ä¸­æ–‡ç¿»è¯‘": list(glossary_data.values())
                    })
                    st.session_state.user_glossary = glossary_data
                    
                    # æ˜¾ç¤ºå¯ç¼–è¾‘çš„è¡¨æ ¼
                    edited_glossary_df = st.data_editor(
                        glossary_df,
                        use_container_width=True,
                        num_rows="dynamic",
                        hide_index=True
                    )
                    
                    # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„è¯æ±‡è¡¨
                    st.session_state.user_glossary = dict(zip(
                        edited_glossary_df['ä¸“æœ‰åè¯'], 
                        edited_glossary_df['ä¸­æ–‡ç¿»è¯‘']
                    ))
            except Exception as e:
                st.error(f"è¯»å–è¯æ±‡è¡¨å‡ºé”™: {str(e)}")
    
    # æ ‡ç­¾é¡µ2ï¼šç¿»è¯‘è®¾ç½®
    with tab2:
        st.header("ç¿»è¯‘è®¾ç½®")
        
        # API é…ç½®ä¿¡æ¯ï¼ˆä»…æ˜¾ç¤ºï¼Œå®é™…é…ç½®åœ¨ .env æ–‡ä»¶ä¸­ï¼‰
        st.subheader("API é…ç½®")
        st.info("API é…ç½®åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®ã€‚")
        
        # ç¿»è¯‘è®¾ç½®
        st.subheader("ç¿»è¯‘å‚æ•°")
        
        # çº¿ç¨‹æ•°
        num_threads = st.slider("çº¿ç¨‹æ•°", min_value=1, max_value=10, value=5, 
                                help="ä½¿ç”¨çš„çº¿ç¨‹æ•°é‡ï¼Œè¶Šå¤šé€Ÿåº¦è¶Šå¿«ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´ API é™æµ")
        
        # æ–­ç‚¹ç»­ä¼ 
        resume_translation = st.checkbox("å¯ç”¨æ–­ç‚¹ç»­ä¼ ", value=True,
                                        help="å¦‚æœç¿»è¯‘è¿‡ç¨‹ä¸­æ–­ï¼Œä¸‹æ¬¡å¯ä»¥ä»æ–­ç‚¹ç»§ç»­")
        
        # ä½¿ç”¨è‡ªå®šä¹‰è¯æ±‡è¡¨
        use_glossary = st.checkbox("ä½¿ç”¨è‡ªå®šä¹‰è¯æ±‡è¡¨", value=True,
                                  help="å°†ä½¿ç”¨ä¸Šä¼ çš„æˆ–æå–çš„è¯æ±‡è¡¨è¿›è¡Œç¿»è¯‘")
    
    # æ ‡ç­¾é¡µ3ï¼šå¼€å§‹ç¿»è¯‘
    with tab3:
        st.header("å¼€å§‹ç¿»è¯‘")
        
        # ç¿»è¯‘çŠ¶æ€
        if "translation_status" not in st.session_state:
            st.session_state.translation_status = "å‡†å¤‡å°±ç»ª"
            st.session_state.translation_progress = 0
            st.session_state.translation_done = False
        
        # æ˜¾ç¤ºç¿»è¯‘çŠ¶æ€
        status_container = st.container()
        progress_bar = st.progress(st.session_state.translation_progress)
        
        # åœæ­¢ç¿»è¯‘æŒ‰é’®ï¼ˆä»…åœ¨ç¿»è¯‘è¿›è¡Œä¸­æ˜¾ç¤ºï¼‰
        if st.session_state.translation_status == "ç¿»è¯‘ä¸­" and not st.session_state.translation_done:
            if st.button("åœæ­¢ç¿»è¯‘"):
                # å‘é€åœæ­¢ç¿»è¯‘çš„ä¿¡å·
                st.session_state.stop_translation = True
                st.session_state.translation_status = "æ­£åœ¨åœæ­¢..."
                status_container.info(f"çŠ¶æ€: {st.session_state.translation_status}")
        
        # å¼€å§‹ç¿»è¯‘æŒ‰é’®
        if st.button("å¼€å§‹ç¿»è¯‘", disabled=(st.session_state.translation_status == "ç¿»è¯‘ä¸­")):
            # é‡ç½®çŠ¶æ€
            st.session_state.translation_status = "ç¿»è¯‘ä¸­"
            st.session_state.translation_progress = 0
            st.session_state.translation_done = False
            st.session_state.stop_translation = False
            
            status_container.info(f"çŠ¶æ€: {st.session_state.translation_status}")
            
            # è·å–ç”¨æˆ·è¯æ±‡è¡¨
            user_glossary = st.session_state.get("user_glossary", None)
            
            # åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨ç¿»è¯‘
            def run_translation():
                try:
                    # å¼€å§‹ç¿»è¯‘
                    translate_epub(
                        input_path, 
                        output_path, 
                        num_threads=num_threads, 
                        user_glossary=user_glossary,
                        resume=resume_translation
                    )
                    # æ›´æ–°çŠ¶æ€
                    st.session_state.translation_status = "ç¿»è¯‘å®Œæˆ"
                    st.session_state.translation_done = True
                    st.session_state.translation_progress = 1.0
                except Exception as e:
                    st.session_state.translation_status = f"ç¿»è¯‘å¤±è´¥: {str(e)}"
                    st.session_state.translation_done = True
            
            # å¯åŠ¨ç¿»è¯‘çº¿ç¨‹
            translate_thread = threading.Thread(target=run_translation)
            translate_thread.start()
        
        # åˆ·æ–°çŠ¶æ€ï¼ˆæ¯3ç§’è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡ï¼‰
        status_container.info(f"çŠ¶æ€: {st.session_state.translation_status}")
        
        # å¦‚æœç¿»è¯‘å®Œæˆï¼Œæä¾›ä¸‹è½½é“¾æ¥
        if st.session_state.translation_done and st.session_state.translation_status == "ç¿»è¯‘å®Œæˆ":
            # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
            st.success("ç¿»è¯‘å·²å®Œæˆï¼")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(output_path, "rb") as f:
                st.download_button(
                    label="ä¸‹è½½ç¿»è¯‘åçš„ EPUB",
                    data=f,
                    file_name=uploaded_file.name.replace('.epub', '_cn.epub'),
                    mime="application/epub+zip"
                )
else:
    # å¦‚æœæ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    st.title("EPUB ç¿»è¯‘å™¨")
    st.markdown("""
    ### ä½¿ç”¨è¯´æ˜
    
    1. åœ¨å·¦ä¾§ä¾§è¾¹æ ä¸Šä¼ ä¸€ä¸ª EPUB æ–‡ä»¶
    2. æå–ä¸“æœ‰åè¯å¹¶è¿›è¡Œç¼–è¾‘ï¼ˆå¯é€‰ï¼‰
    3. ä¸Šä¼ è‡ªå®šä¹‰è¯æ±‡è¡¨ï¼ˆå¯é€‰ï¼Œæ”¯æŒJSONå’ŒExcelæ ¼å¼ï¼‰
    4. è°ƒæ•´ç¿»è¯‘è®¾ç½®
    5. å¼€å§‹ç¿»è¯‘å¹¶ä¸‹è½½ç»“æœ
    
    ### ç‰¹æ€§
    
    * ä½¿ç”¨ OpenAI API è¿›è¡Œé«˜è´¨é‡ç¿»è¯‘
    * æ”¯æŒä¸“æœ‰åè¯è¯å…¸
    * æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    * å¤šçº¿ç¨‹åŠ é€Ÿç¿»è¯‘è¿‡ç¨‹
    """)
    
    # æ˜¾ç¤ºç¯å¢ƒé…ç½®è¦æ±‚
    st.subheader("ç¯å¢ƒé…ç½®")
    st.markdown("""
    åœ¨è¿è¡Œæ­¤åº”ç”¨å‰ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®é…ç½® `.env` æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«ä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š
    
    **é…ç½®ç¤ºä¾‹ï¼š**
    ```
    API_KEY=your_api_key_here
    MODEL_NAME=gpt-3.5-turbo
    # å¦‚æœä½¿ç”¨ä»£ç†æœåŠ¡å™¨
    BASE_URL=https://your-proxy-server.com/v1
    ```
    """) 